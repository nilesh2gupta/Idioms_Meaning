{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "BaKfM01b3kB_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Loading"
      ],
      "metadata": {
        "id": "kC5XCw_drUnD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/idioms_nlp.csv',encoding='UTF-8')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "wuFZhD8045bH",
        "outputId": "0efc3a94-3885-4a5f-c9dc-310c362a6736"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     S.No.                  Idioms                      Hindi Meaning  \\\n",
              "0      1.0     A hard nut to crack                       xaHkhj leL;k   \n",
              "1      2.0    A thorn in the flesh    dke esa ges’kk gksus okyh ck/kk   \n",
              "2      3.0  At one’s beck and call  fu;a=.k esa gksuk] vkKk esa gksuk   \n",
              "3      4.0            An acid test                     xaHkhj ijh{k.k   \n",
              "4      5.0      All eye for an eye                      tSls dks rSlk   \n",
              "..     ...                     ...                                ...   \n",
              "804  990.0             alma matter                         ekr`laLFkk   \n",
              "805  991.0                go dutch                          lk>k djuk   \n",
              "806  992.0            close fisted                              datwl   \n",
              "807  993.0            high and dry                            fu%lgk;   \n",
              "808  994.0          make a beeline                         Hkkxe&Hkkx   \n",
              "\n",
              "                                       English Meaning  Unnamed: 4  \n",
              "0                                  A difficult problem         NaN  \n",
              "1                       A constant source of annoyance         NaN  \n",
              "2                                  Under one’s control         NaN  \n",
              "3                                      A critical test         NaN  \n",
              "4                                          Tit for tat         NaN  \n",
              "..                                                 ...         ...  \n",
              "804  the school, college or university that somebod...         NaN  \n",
              "805                   to share the cost of sth with sb         NaN  \n",
              "806                    not willing to spend much money         NaN  \n",
              "807     in a difficult situation without money or help         NaN  \n",
              "808  to go straight towards sth as\\nquickly you can...         NaN  \n",
              "\n",
              "[809 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1ff0717e-9908-4019-b771-50a454374095\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>S.No.</th>\n",
              "      <th>Idioms</th>\n",
              "      <th>Hindi Meaning</th>\n",
              "      <th>English Meaning</th>\n",
              "      <th>Unnamed: 4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>A hard nut to crack</td>\n",
              "      <td>xaHkhj leL;k</td>\n",
              "      <td>A difficult problem</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.0</td>\n",
              "      <td>A thorn in the flesh</td>\n",
              "      <td>dke esa ges’kk gksus okyh ck/kk</td>\n",
              "      <td>A constant source of annoyance</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.0</td>\n",
              "      <td>At one’s beck and call</td>\n",
              "      <td>fu;a=.k esa gksuk] vkKk esa gksuk</td>\n",
              "      <td>Under one’s control</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.0</td>\n",
              "      <td>An acid test</td>\n",
              "      <td>xaHkhj ijh{k.k</td>\n",
              "      <td>A critical test</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>All eye for an eye</td>\n",
              "      <td>tSls dks rSlk</td>\n",
              "      <td>Tit for tat</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>804</th>\n",
              "      <td>990.0</td>\n",
              "      <td>alma matter</td>\n",
              "      <td>ekr`laLFkk</td>\n",
              "      <td>the school, college or university that somebod...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>805</th>\n",
              "      <td>991.0</td>\n",
              "      <td>go dutch</td>\n",
              "      <td>lk&gt;k djuk</td>\n",
              "      <td>to share the cost of sth with sb</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>806</th>\n",
              "      <td>992.0</td>\n",
              "      <td>close fisted</td>\n",
              "      <td>datwl</td>\n",
              "      <td>not willing to spend much money</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>807</th>\n",
              "      <td>993.0</td>\n",
              "      <td>high and dry</td>\n",
              "      <td>fu%lgk;</td>\n",
              "      <td>in a difficult situation without money or help</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>808</th>\n",
              "      <td>994.0</td>\n",
              "      <td>make a beeline</td>\n",
              "      <td>Hkkxe&amp;Hkkx</td>\n",
              "      <td>to go straight towards sth as\\nquickly you can...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>809 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1ff0717e-9908-4019-b771-50a454374095')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1ff0717e-9908-4019-b771-50a454374095 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1ff0717e-9908-4019-b771-50a454374095');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-678bb6cb-19ba-4d57-930c-663a4264ccb2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-678bb6cb-19ba-4d57-930c-663a4264ccb2')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-678bb6cb-19ba-4d57-930c-663a4264ccb2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Preprocessing"
      ],
      "metadata": {
        "id": "FA2FsyWgrc9H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.drop(['S.No.','Hindi Meaning','Unnamed: 4'],axis=1)"
      ],
      "metadata": {
        "id": "ieZSqHimIA6y"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "UJlEjEUeIA-7",
        "outputId": "b4d29cfc-0151-426c-eefb-e86db866118e"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                            Idioms  \\\n",
              "0              A hard nut to crack   \n",
              "1             A thorn in the flesh   \n",
              "2           At one’s beck and call   \n",
              "3                     An acid test   \n",
              "4               All eye for an eye   \n",
              "5                          At once   \n",
              "6                          At home   \n",
              "7                       All in all   \n",
              "8                  Achilles’ heels   \n",
              "9                 Add fuel to fire   \n",
              "10                An arm chair job   \n",
              "11                 An axe to grind   \n",
              "12                    An iron will   \n",
              "13                    An old flame   \n",
              "14  An old head on young shoulders   \n",
              "15                 An olive branch   \n",
              "16                Apple of discord   \n",
              "17              Apple of one’s eye   \n",
              "18                 Apple pie order   \n",
              "19                       At a lose   \n",
              "\n",
              "                                      English Meaning  \n",
              "0                                 A difficult problem  \n",
              "1                      A constant source of annoyance  \n",
              "2                                 Under one’s control  \n",
              "3                                     A critical test  \n",
              "4                                         Tit for tat  \n",
              "5                 At the same time, promptly, instant  \n",
              "6                                         Comfortable  \n",
              "7                                      Most important  \n",
              "8                          A small but fatal weakness  \n",
              "9                              To make a matter worse  \n",
              "10                  Good income job with high comfort  \n",
              "11                 Something done for selfish reasons  \n",
              "12                                  Strong will power  \n",
              "13  A person, one had a romantic relationship with...  \n",
              "14  A child or young person who thinks and talks l...  \n",
              "15                         Peace request/peace treaty  \n",
              "16                                  Matter of dispute  \n",
              "17                           Very lovable/dearest one  \n",
              "18                                  In good condition  \n",
              "19                             To be unable to decide  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-92f01c82-ddd6-46f3-a00c-730eddb824f1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Idioms</th>\n",
              "      <th>English Meaning</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A hard nut to crack</td>\n",
              "      <td>A difficult problem</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A thorn in the flesh</td>\n",
              "      <td>A constant source of annoyance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>At one’s beck and call</td>\n",
              "      <td>Under one’s control</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>An acid test</td>\n",
              "      <td>A critical test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>All eye for an eye</td>\n",
              "      <td>Tit for tat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>At once</td>\n",
              "      <td>At the same time, promptly, instant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>At home</td>\n",
              "      <td>Comfortable</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>All in all</td>\n",
              "      <td>Most important</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Achilles’ heels</td>\n",
              "      <td>A small but fatal weakness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Add fuel to fire</td>\n",
              "      <td>To make a matter worse</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>An arm chair job</td>\n",
              "      <td>Good income job with high comfort</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>An axe to grind</td>\n",
              "      <td>Something done for selfish reasons</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>An iron will</td>\n",
              "      <td>Strong will power</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>An old flame</td>\n",
              "      <td>A person, one had a romantic relationship with...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>An old head on young shoulders</td>\n",
              "      <td>A child or young person who thinks and talks l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>An olive branch</td>\n",
              "      <td>Peace request/peace treaty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Apple of discord</td>\n",
              "      <td>Matter of dispute</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Apple of one’s eye</td>\n",
              "      <td>Very lovable/dearest one</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Apple pie order</td>\n",
              "      <td>In good condition</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>At a lose</td>\n",
              "      <td>To be unable to decide</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-92f01c82-ddd6-46f3-a00c-730eddb824f1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-92f01c82-ddd6-46f3-a00c-730eddb824f1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-92f01c82-ddd6-46f3-a00c-730eddb824f1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-018e4235-d08a-46be-b151-cd570205801d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-018e4235-d08a-46be-b151-cd570205801d')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-018e4235-d08a-46be-b151-cd570205801d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sU8N0oXZIKXJ",
        "outputId": "7b043932-46e6-40af-c9c5-123326366357"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 809 entries, 0 to 808\n",
            "Data columns (total 2 columns):\n",
            " #   Column           Non-Null Count  Dtype \n",
            "---  ------           --------------  ----- \n",
            " 0   Idioms           809 non-null    object\n",
            " 1   English Meaning  808 non-null    object\n",
            "dtypes: object(2)\n",
            "memory usage: 12.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZ7zZNslI0d6",
        "outputId": "8474c768-0561-40b7-9704-b38f7a63163d"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Idioms             0\n",
              "English Meaning    1\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=df[df['Idioms']!='Cave in']\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08W4TJ9gaC7_",
        "outputId": "f5b6ed35-001e-4422-cf3a-832728e85732"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 808 entries, 0 to 808\n",
            "Data columns (total 2 columns):\n",
            " #   Column           Non-Null Count  Dtype \n",
            "---  ------           --------------  ----- \n",
            " 0   Idioms           808 non-null    object\n",
            " 1   English Meaning  808 non-null    object\n",
            "dtypes: object(2)\n",
            "memory usage: 18.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def remove_brackets(text):\n",
        "    return re.sub(r'\\([^)]*\\)', '', text)"
      ],
      "metadata": {
        "id": "sCcOWws_-KGS"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Idioms']=df['Idioms'].apply(remove_brackets)"
      ],
      "metadata": {
        "id": "6C2uFz_i-BxV"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Idioms']=df['Idioms'].apply(lambda x:'<start> '+ x +' <end>')\n",
        "df['English Meaning']=df['English Meaning'].apply(lambda x:'<start> '+ x +' <end>')"
      ],
      "metadata": {
        "id": "hnRJGO0lD27m"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_word=max(df['English Meaning'].str.split().str.len())\n",
        "min_word=min(df['English Meaning'].str.split().str.len())\n",
        "print(\"Max words=\",int(max_word))\n",
        "print(\"Min words=\",int(min_word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8y64jm16I0hY",
        "outputId": "ec409810-d891-49f7-9cf5-b628d4909773"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max words= 22\n",
            "Min words= 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_words=max(df['Idioms'].str.split().str.len())\n",
        "min_words=min(df['Idioms'].str.split().str.len())\n",
        "print(\"Max words=\",max_words)\n",
        "print(\"Min words=\",min_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dxc0eecxI0lN",
        "outputId": "cec9a22b-f43d-4cdd-95a8-69110d338f73"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max words= 11\n",
            "Min words= 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_idioms=[]\n",
        "list_mean=[]\n",
        "def formlist(text,list):\n",
        "    list.append(text)\n"
      ],
      "metadata": {
        "id": "-iLd8fAqIKax"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Idioms'].apply(lambda x:formlist(x,list_idioms))\n",
        "df['English Meaning'].apply(lambda x:formlist(x,list_mean))"
      ],
      "metadata": {
        "id": "nFfmyI06IKoX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(list_idioms[0],\"  \",list_mean[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyN8qfW3A8kE",
        "outputId": "2368f6f1-36e3-48c0-aef3-8ea9dd7dee26"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<start> A hard nut to crack <end>    <start> A difficult problem <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "cNgf4o6GAY27"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def total_words(list):\n",
        "    tokenizer=Tokenizer(num_words=100)\n",
        "    tokenizer.fit_on_texts(list)\n",
        "    return max(tokenizer.word_index.values())"
      ],
      "metadata": {
        "id": "c_7dp6GgKl8S"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_idioms_word=total_words(list_idioms)\n",
        "total_mean_word=total_words(list_mean)\n",
        "print('total_words_in_idioms=',total_idioms_word)\n",
        "print('total_words_in_meaning=',total_mean_word)"
      ],
      "metadata": {
        "id": "p2LrIO6wKowP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "437a36e1-6fda-466f-dfa8-855af08b1dfc"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_words_in_idioms= 959\n",
            "total_words_in_meaning= 1268\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tokenizer_for_idioms_&_their_meaning**"
      ],
      "metadata": {
        "id": "w2NQi8ohrm-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "idioms_tokenizer=Tokenizer(total_idioms_word)\n",
        "idioms_tokenizer.fit_on_texts(list_idioms)\n",
        "\n",
        "mean_tokenizer=Tokenizer(total_mean_word)\n",
        "mean_tokenizer.fit_on_texts(list_mean)"
      ],
      "metadata": {
        "id": "3ZjBfteJZ2vX"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_pad(list,max_len,num_words):\n",
        "    tokenizer=Tokenizer(num_words=num_words)\n",
        "    tokenizer.fit_on_texts(list)\n",
        "    sequence=tokenizer.texts_to_sequences(list)\n",
        "    padded=pad_sequences(sequence,padding='post',maxlen=max_len)\n",
        "    return padded"
      ],
      "metadata": {
        "id": "y_Kw6HojPtE-"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idioms_pad=tokenize_pad(list_idioms,11,total_idioms_word)"
      ],
      "metadata": {
        "id": "q-bZB8UrAp3h"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_pad=tokenize_pad(list_mean,22,total_mean_word)"
      ],
      "metadata": {
        "id": "GZXLanJK-NeK"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#** Model Architecture(Seq2Seq_with_teacher_forcing) **"
      ],
      "metadata": {
        "id": "641AB4UNE6_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Embedding, BatchNormalization, LSTM, Dense\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Nadam\n",
        "\n",
        "latent_dim = 100\n",
        "doc_length = 11\n",
        "# Encoder model\n",
        "encoder_input = Input(shape=(doc_length,), name='encoder_input')\n",
        "x = Embedding(total_idioms_word, latent_dim, name='Idioms_word_embedding')(encoder_input)\n",
        "x = BatchNormalization(name='Scaling_idioms_vector')(x)\n",
        "x=LSTM(latent_dim,return_sequences=True,name='Encoder_LSTM1')(x)\n",
        "_,state_h,state_c = LSTM(latent_dim, return_state=True,return_sequences=True, name='Encoder_LSTM2')(x)\n",
        "encoder_model = Model(inputs=encoder_input, outputs=[state_h,state_c], name='Encoder_Model')\n",
        "encoder_out_h,encoder_out_c= encoder_model(encoder_input)\n",
        "\n",
        "# Decoder model\n",
        "decoder_input = Input(shape=(None,), name='Decoder_input')\n",
        "y = Embedding(total_mean_word, latent_dim, name='Mean_word_embedding')(decoder_input)\n",
        "y = BatchNormalization(name='Scaling_mean_vector')(y)\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, name='Decoder_LSTM')\n",
        "output_n, _, _ = decoder_lstm(y, initial_state=[encoder_out_h,encoder_out_c])\n",
        "output_norm = BatchNormalization(name='Decoder_lstm_output_norm')(output_n)\n",
        "\n",
        "# Dense layer\n",
        "dense_layer = Dense(total_mean_word, activation='softmax', name='Final_dense_layer')\n",
        "prob_out = dense_layer(output_norm)\n",
        "\n",
        "# Sequence_to_Sequence_Model\n",
        "seq2seq_Model = Model([encoder_input, decoder_input], prob_out)\n",
        "seq2seq_Model.compile(optimizer=Nadam(learning_rate=0.001), loss='sparse_categorical_crossentropy')\n",
        "seq2seq_Model.summary()\n"
      ],
      "metadata": {
        "id": "Pdqr-ljT-NlM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df0aac8a-abec-4740-c857-231c9440e05b"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " Decoder_input (InputLayer)  [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " Mean_word_embedding (Embed  (None, None, 100)            126800    ['Decoder_input[0][0]']       \n",
            " ding)                                                                                            \n",
            "                                                                                                  \n",
            " encoder_input (InputLayer)  [(None, 11)]                 0         []                            \n",
            "                                                                                                  \n",
            " Scaling_mean_vector (Batch  (None, None, 100)            400       ['Mean_word_embedding[0][0]'] \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " Encoder_Model (Functional)  [(None, 100),                257100    ['encoder_input[0][0]']       \n",
            "                              (None, 100)]                                                        \n",
            "                                                                                                  \n",
            " Decoder_LSTM (LSTM)         [(None, None, 100),          80400     ['Scaling_mean_vector[0][0]', \n",
            "                              (None, 100),                           'Encoder_Model[0][0]',       \n",
            "                              (None, 100)]                           'Encoder_Model[0][1]']       \n",
            "                                                                                                  \n",
            " Decoder_lstm_output_norm (  (None, None, 100)            400       ['Decoder_LSTM[0][0]']        \n",
            " BatchNormalization)                                                                              \n",
            "                                                                                                  \n",
            " Final_dense_layer (Dense)   (None, None, 1268)           128068    ['Decoder_lstm_output_norm[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 593168 (2.26 MB)\n",
            "Trainable params: 592568 (2.26 MB)\n",
            "Non-trainable params: 600 (2.34 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.save('Idioms_vecs.npy',idioms_pad)\n",
        "np.save('Mean_vecs.npy',mean_pad)\n",
        "\n",
        "\n",
        "def load_encoder_inputs(encoder_np_vecs='Idioms_vecs.npy'):\n",
        "    vectorized_body=np.load(encoder_np_vecs)\n",
        "    encoder_input_data=vectorized_body\n",
        "    doc_length=encoder_input_data.shape[1]\n",
        "    print(f'Shape of the encoder input:{encoder_input_data.shape}')\n",
        "    return encoder_input_data ,doc_length\n",
        "\n",
        "\n",
        "def load_decoder_inputs(decoder_np_vecs='Mean_vecs.npy'):\n",
        "    vectorized_title=np.load(decoder_np_vecs)\n",
        "    decoder_input_data=vectorized_title[:,:-1]\n",
        "    decoder_target_data=vectorized_title[:,1:]\n",
        "    print(f'Shape of the decoder input:{decoder_input_data.shape}')\n",
        "    print(f'Shape of the decoder target :{decoder_target_data.shape}')\n",
        "    return decoder_input_data,decoder_target_data\n",
        "\n",
        "decoder_input_data,decoder_target_data=load_decoder_inputs('Mean_vecs.npy')\n",
        "encoder_input_data,doc_length=load_encoder_inputs('Idioms_vecs.npy')\n"
      ],
      "metadata": {
        "id": "mzmF1xNWMtbT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "246eb69a-581b-4ce8-cd10-14866081d678"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the decoder input:(808, 21)\n",
            "Shape of the decoder target :(808, 21)\n",
            "Shape of the encoder input:(808, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model_training"
      ],
      "metadata": {
        "id": "0M-0xCbpsz4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import CSVLogger,ModelCheckpoint\n",
        "script_name_base='seq2seq'\n",
        "csv_logger=CSVLogger('{:}.log'.format(script_name_base))\n",
        "model_checkpoint=ModelCheckpoint('{:}.epoch{{epoch:02d}}-val{{val_loss:.5f}}.hdf5'.format(script_name_base),save_best_only=True)\n",
        "batch_size=100\n",
        "epochs=100\n",
        "history=seq2seq_Model.fit([encoder_input_data,decoder_input_data], np.expand_dims(decoder_target_data,axis=1),batch_size=batch_size,epochs=epochs,validation_split=0.12,\n",
        "                          callbacks=[csv_logger,model_checkpoint])"
      ],
      "metadata": {
        "id": "dAa7qWzJMte2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a0ed924-7660-4e58-b70a-6e441fd4e7f8"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 13s 425ms/step - loss: 6.8403 - val_loss: 7.0903\n",
            "Epoch 2/100\n",
            "1/8 [==>...........................] - ETA: 1s - loss: 6.0581"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 1s 155ms/step - loss: 5.6768 - val_loss: 7.0177\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 2s 224ms/step - loss: 4.8803 - val_loss: 6.9174\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 2s 239ms/step - loss: 4.1303 - val_loss: 6.7878\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 1s 156ms/step - loss: 3.3890 - val_loss: 6.6251\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 1s 154ms/step - loss: 2.7015 - val_loss: 6.4368\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 1s 152ms/step - loss: 2.1528 - val_loss: 6.2548\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 1s 153ms/step - loss: 1.7846 - val_loss: 6.0872\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 1s 167ms/step - loss: 1.5768 - val_loss: 5.9354\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 1s 156ms/step - loss: 1.4509 - val_loss: 5.8221\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 1s 155ms/step - loss: 1.3649 - val_loss: 5.7199\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 1s 181ms/step - loss: 1.2984 - val_loss: 5.6617\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 2s 277ms/step - loss: 1.2353 - val_loss: 5.5973\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 1s 156ms/step - loss: 1.1801 - val_loss: 5.5505\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 1s 157ms/step - loss: 1.1184 - val_loss: 5.4991\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 1s 154ms/step - loss: 1.0574 - val_loss: 5.4589\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 1s 157ms/step - loss: 0.9964 - val_loss: 5.4100\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 1s 154ms/step - loss: 0.9394 - val_loss: 5.2983\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 1s 153ms/step - loss: 0.8849 - val_loss: 5.2523\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 1s 155ms/step - loss: 0.8142 - val_loss: 5.1705\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 1s 155ms/step - loss: 0.7468 - val_loss: 5.1279\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 2s 267ms/step - loss: 0.6845 - val_loss: 5.0541\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 2s 175ms/step - loss: 0.6210 - val_loss: 4.9973\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 1s 153ms/step - loss: 0.5657 - val_loss: 4.9159\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 1s 156ms/step - loss: 0.5094 - val_loss: 4.8387\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 1s 156ms/step - loss: 0.4551 - val_loss: 4.7647\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 1s 157ms/step - loss: 0.4071 - val_loss: 4.6873\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 1s 158ms/step - loss: 0.3615 - val_loss: 4.6119\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 1s 156ms/step - loss: 0.3162 - val_loss: 4.5126\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 1s 156ms/step - loss: 0.2769 - val_loss: 4.4316\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 2s 252ms/step - loss: 0.2417 - val_loss: 4.3546\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 2s 212ms/step - loss: 0.2100 - val_loss: 4.2701\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 1s 155ms/step - loss: 0.1853 - val_loss: 4.1813\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 1s 154ms/step - loss: 0.1624 - val_loss: 4.0841\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 1s 157ms/step - loss: 0.1433 - val_loss: 4.0039\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 1s 158ms/step - loss: 0.1256 - val_loss: 3.9279\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 1s 154ms/step - loss: 0.1092 - val_loss: 3.8455\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 1s 154ms/step - loss: 0.0970 - val_loss: 3.7465\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 1s 156ms/step - loss: 0.0856 - val_loss: 3.6723\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 2s 215ms/step - loss: 0.0787 - val_loss: 3.6000\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 2s 246ms/step - loss: 0.0719 - val_loss: 3.5117\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 1s 153ms/step - loss: 0.0636 - val_loss: 3.4567\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 2s 194ms/step - loss: 0.0590 - val_loss: 3.3953\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 2s 260ms/step - loss: 0.0556 - val_loss: 3.3166\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 2s 227ms/step - loss: 0.0514 - val_loss: 3.2207\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 1s 157ms/step - loss: 0.0500 - val_loss: 3.1925\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 1s 158ms/step - loss: 0.0462 - val_loss: 3.1266\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 2s 216ms/step - loss: 0.0422 - val_loss: 3.0654\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 2s 255ms/step - loss: 0.0396 - val_loss: 3.0246\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 1s 154ms/step - loss: 0.0386 - val_loss: 2.9750\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 1s 154ms/step - loss: 0.0354 - val_loss: 2.9262\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 1s 156ms/step - loss: 0.0332 - val_loss: 2.8843\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 1s 166ms/step - loss: 0.0318 - val_loss: 2.8569\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 1s 158ms/step - loss: 0.0303 - val_loss: 2.8157\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 1s 159ms/step - loss: 0.0297 - val_loss: 2.7713\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 1s 170ms/step - loss: 0.0288 - val_loss: 2.7504\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 2s 193ms/step - loss: 0.0272 - val_loss: 2.7274\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 2s 268ms/step - loss: 0.0251 - val_loss: 2.6895\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 1s 156ms/step - loss: 0.0236 - val_loss: 2.6617\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 1s 163ms/step - loss: 0.0232 - val_loss: 2.6522\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 1s 158ms/step - loss: 0.0232 - val_loss: 2.6034\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 1s 151ms/step - loss: 0.0220 - val_loss: 2.6150\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 1s 156ms/step - loss: 0.0212 - val_loss: 2.5871\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 1s 161ms/step - loss: 0.0207 - val_loss: 2.5625\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 1s 161ms/step - loss: 0.0212 - val_loss: 2.5557\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 1s 158ms/step - loss: 0.0217 - val_loss: 2.5664\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 2s 286ms/step - loss: 0.0216 - val_loss: 2.5450\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 1s 157ms/step - loss: 0.0204 - val_loss: 2.5384\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 1s 147ms/step - loss: 0.0189 - val_loss: 2.5482\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 1s 151ms/step - loss: 0.0182 - val_loss: 2.5500\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 1s 147ms/step - loss: 0.0172 - val_loss: 2.5465\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 1s 148ms/step - loss: 0.0164 - val_loss: 2.5652\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 1s 150ms/step - loss: 0.0165 - val_loss: 2.5733\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 1s 146ms/step - loss: 0.0168 - val_loss: 2.5995\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 1s 147ms/step - loss: 0.0169 - val_loss: 2.6030\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 2s 217ms/step - loss: 0.0162 - val_loss: 2.6389\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 2s 228ms/step - loss: 0.0168 - val_loss: 2.6481\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 1s 149ms/step - loss: 0.0156 - val_loss: 2.6638\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 1s 148ms/step - loss: 0.0151 - val_loss: 2.6879\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 1s 146ms/step - loss: 0.0147 - val_loss: 2.7033\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 1s 147ms/step - loss: 0.0146 - val_loss: 2.7283\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 1s 147ms/step - loss: 0.0145 - val_loss: 2.7561\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 1s 149ms/step - loss: 0.0135 - val_loss: 2.7769\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 1s 147ms/step - loss: 0.0135 - val_loss: 2.7831\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 1s 152ms/step - loss: 0.0130 - val_loss: 2.8316\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 2s 252ms/step - loss: 0.0126 - val_loss: 2.8437\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 2s 194ms/step - loss: 0.0124 - val_loss: 2.8711\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 1s 147ms/step - loss: 0.0132 - val_loss: 2.8979\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 1s 146ms/step - loss: 0.0136 - val_loss: 2.9005\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 1s 149ms/step - loss: 0.0130 - val_loss: 2.9168\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 1s 150ms/step - loss: 0.0133 - val_loss: 2.9340\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 1s 149ms/step - loss: 0.0123 - val_loss: 2.9638\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 1s 147ms/step - loss: 0.0120 - val_loss: 2.9938\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 1s 144ms/step - loss: 0.0114 - val_loss: 2.9991\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 1s 163ms/step - loss: 0.0114 - val_loss: 3.0284\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 2s 259ms/step - loss: 0.0110 - val_loss: 3.0425\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 1s 151ms/step - loss: 0.0109 - val_loss: 3.0612\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 1s 147ms/step - loss: 0.0115 - val_loss: 3.0916\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 1s 146ms/step - loss: 0.0137 - val_loss: 3.0838\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 1s 148ms/step - loss: 0.0152 - val_loss: 3.0909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Inference_Class_with_beam_search_decoding"
      ],
      "metadata": {
        "id": "wxOHIFE3sYJx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "\n",
        "class IdiomsMeanInference:\n",
        "    def __init__(self, model_path, idioms_tokenizer, mean_tokenizer, doc_length, beam_width=2):\n",
        "        self.model = load_model(model_path)\n",
        "        self.idioms_tokenizer = idioms_tokenizer\n",
        "        self.mean_tokenizer = mean_tokenizer\n",
        "        self.doc_length = doc_length\n",
        "        self.beam_width = beam_width\n",
        "\n",
        "    def tokenize_idioms(self, idioms_text):\n",
        "        idioms_text = '<start> ' + idioms_text + ' <end>'\n",
        "        sequences = self.idioms_tokenizer.texts_to_sequences([idioms_text])\n",
        "        padded_sequences = pad_sequences(sequences, maxlen=self.doc_length, padding='post')\n",
        "        return padded_sequences\n",
        "\n",
        "    def beam_search(self, encoded_idioms, max_length=5):\n",
        "        start_token = self.mean_tokenizer.word_index['start']\n",
        "        end_token = self.mean_tokenizer.word_index['end']\n",
        "\n",
        "        sequences = [[start_token]]\n",
        "        scores = [0]\n",
        "\n",
        "        while len(sequences[0]) < max_length:\n",
        "            all_candidates = []\n",
        "\n",
        "            for i in range(len(sequences)):\n",
        "                sequence = sequences[i]\n",
        "                last_token = sequence[-1]\n",
        "                if last_token == end_token:\n",
        "                    continue\n",
        "\n",
        "                target_seq = np.zeros((1, len(sequence)))\n",
        "                for t, token in enumerate(sequence):\n",
        "                    target_seq[0, t] = token\n",
        "\n",
        "                predictions = self.model.predict([encoded_idioms, target_seq])\n",
        "                next_token_probs = predictions[0, -1, :]\n",
        "                best_tokens = np.argsort(next_token_probs)[-self.beam_width:]\n",
        "\n",
        "                for token in best_tokens:\n",
        "                    new_sequence = sequence + [token]\n",
        "                    new_score = scores[i] - np.log(next_token_probs[token])\n",
        "                    all_candidates.append((new_sequence, new_score))\n",
        "\n",
        "            if not all_candidates:\n",
        "                break\n",
        "\n",
        "            ordered = sorted(all_candidates, key=lambda tup: tup[1])\n",
        "            sequences = [seq for seq, _ in ordered]\n",
        "            scores = [score for _, score in ordered]\n",
        "\n",
        "        best_sequence = sequences[0]\n",
        "        decoded_sequence = [self.mean_tokenizer.index_word[token] for token in best_sequence]\n",
        "        return ' '.join(decoded_sequence[1:-1])\n",
        "\n",
        "    def generate_meaning(self, idioms_text):\n",
        "        encoded_idioms = self.tokenize_idioms(idioms_text)\n",
        "        generated_meaning = self.beam_search(encoded_idioms)\n",
        "        return generated_meaning\n",
        "\n"
      ],
      "metadata": {
        "id": "bLXBwxxSlpYn"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Usage Space"
      ],
      "metadata": {
        "id": "LgaFZ_iNsr-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "idioms_mean_inference = IdiomsMeanInference('/content/seq2seq.epoch70-val2.52423.hdf5', idioms_tokenizer, mean_tokenizer, doc_length, beam_width=3)\n",
        "idioms_text = \"An iron will\"\n",
        "predicted_meaning = idioms_mean_inference.generate_meaning(idioms_text)\n",
        "print(\"Predicted Meaning:\", predicted_meaning)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXgBj-dfoAEZ",
        "outputId": "93fa1a6d-7565-4d36-ded7-068fe68e630e"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Predicted Meaning: strong will power\n"
          ]
        }
      ]
    }
  ]
}